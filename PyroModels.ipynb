{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46487c67",
   "metadata": {},
   "source": [
    "# Probabilistic Programming in Pyro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "20873088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as torch_functional\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.contrib.examples.util  # patches torchvision\n",
    "from pyro.contrib.examples.util import MNIST\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(0)\n",
    "pyro.set_rng_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fb244a",
   "metadata": {},
   "source": [
    "[Pyro](https://pyro.ai/) is a universal probabilistic programming language built in Python that uses PyTorch as its backend. Among its advantages are that it's:\n",
    " + **Universal**: it can represent any computable probability distribution\n",
    " + **Scalable**: scales to large data sets with little overhead\n",
    " + **Minimal**: implemented with a small core of powerful, composable abstractions\n",
    " \n",
    "A feature of Pyro making it particularly appealing is the ease in developing deep probabilistic models. Seamless integration with PyTorch makes this task trivial in Pyro, thus bridging the world of Bayesian modelling and deep learning. To illustrate this we'll develop an implementation of the Variational Autoencoder (VAE) first in PyTorch, and follow that up with an implementation in Pyro. This will allow us to objectively assess the advantages/disadvantages of one or the other approach. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499f6c61",
   "metadata": {},
   "source": [
    "# VAE: A Refresher on Theory\n",
    "The variational autoencoder (VAE) is arguably the simplest setup that realizes deep probabilistic modeling. Below can be seen a PGM of the simplest form of the model. Having observed $N$ data points denoted $x_i$, we pose a model where each datapoint is generated by a latent random variable $z_i$. There is also a parameter $\\theta$, which is global in the sense that all the datapoints depend on it.\n",
    "\n",
    "<img src=\"https://pyro.ai/examples/_static/img/vae_model.png\" alt=\"drawing\" width=\"300\"/>\n",
    "\n",
    "We allow $x_i$ to depend on $z_i$ in a complex, non-linear way, and this mapping is usually implemented with a deep neural network with parameters $\\theta$. This complexity makes the models more powerful, but also makes inference more challenging. The joint distribution can be factorized as:\n",
    "$$\n",
    "    p(\\mathbf{x}, \\mathbf{z}) = \\prod_{i=1}^N p_{\\theta} (\\mathbf{x}_i \\mid \\mathbf{z}_i) p (\\mathbf{z}_i)\n",
    "$$\n",
    "\n",
    "The job of inference is to recover a \"sensible\" posterior over the latent variables. Just as $x_i$ depends on $z_i$ in a complex way, so might we expect the posterior over $z_i$s to be complex, and inference challenging. Working under the dome of variational inference, we need to define a family of distribution as potential posteriors over the latents. \n",
    "\n",
    "We'll use ***amortized inference***. In amortized inference we introduce a single set of variational parameters $\\phi$ for **ALL** data points. The alternative would be to have variational parameters $\\lambda_i$ for each data point. This would, however, make it impossible to scale to large datasets, as also the parameter space would explode in size. To parameterize the variational family we'll use a deep neural network.\n",
    "\n",
    "<img src=\"https://pyro.ai/examples/_static/img/vae_guide.png\" alt=\"drawing\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1720be16",
   "metadata": {},
   "source": [
    "# The ABCs of PyTorch\n",
    "Before diving into the PyTorch implementation of the VAE, we'll look at some core concepts and abstractions in PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c470734",
   "metadata": {},
   "source": [
    "### Tensors\n",
    "Tensors are a specialized data structure that are very similar to arrays and matrices. Other representations of arrays and matrices you might have seen in Python are in numpy, for example. In PyTorch tensors are used to encode the inputs and outputs of a model, as well as the model’s parameters. \n",
    "\n",
    "Unlike arrays in numpy, Torch tensors can *run on GPUs or other hardware accelerators*, and are also optimized for *automatic differentiation*, which are and were both fundamental for the flourishing of deep learning in recent decades. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "c549a954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor from list: tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "\n",
      "Tensor from NP array: tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "\n",
      "Numpy array from Tensor: [[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor from an nested list of numbers\n",
    "data = [[1, 2],[3, 4]]\n",
    "x_data = torch.Tensor(data)\n",
    "print(f\"Tensor from list: {x_data}\")\n",
    "print()\n",
    "\n",
    "# Convert a numpy array to a tensor\n",
    "np_array = numpy.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "print(f\"Tensor from NP array: {x_np}\")\n",
    "print()\n",
    "\n",
    "# Convert a tensor to a numpy array\n",
    "np_array_tensor = x_np.numpy()\n",
    "print(f\"Numpy array from Tensor: {np_array_tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "a3fd1acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random tensor: tensor([[0.8198, 0.9971, 0.6984],\n",
      "        [0.5675, 0.8352, 0.2056]])\n",
      "Ones tensor: tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "Zeros tensor: tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "\n",
      "The properties of a tensor:\n",
      "Shape of tensor: torch.Size([2, 3])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "shape = (2,3,)\n",
    "\n",
    "rand_tensor = torch.rand(shape)  # A tensor of random numbers from the Uniform distribution on [0, 1)\n",
    "ones_tensor = torch.ones(shape)  # A tensor of 1s\n",
    "zeros_tensor = torch.zeros(shape)  # A tensor of 0s\n",
    "\n",
    "print(f\"Random tensor: {rand_tensor}\")\n",
    "print(f\"Ones tensor: {ones_tensor}\")\n",
    "print(f\"Zeros tensor: {zeros_tensor}\")\n",
    "\n",
    "print()\n",
    "print(\"The properties of a tensor:\")\n",
    "print(f\"Shape of tensor: {rand_tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {rand_tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {rand_tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "cf580e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device tensor is stored on: cpu\n",
      "\n",
      "Indexing and slicing:\n",
      "First row: tensor([1., 1., 1., 1.])\n",
      "First column: tensor([1., 1., 1., 1.])\n",
      "Last column: tensor([1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We move our tensor to the GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    rand_tensor = rand_tensor.to(\"cuda\")\n",
    "    \n",
    "print(f\"Device tensor is stored on: {rand_tensor.device}\")\n",
    "\n",
    "\n",
    "tensor = torch.ones(4, 4)\n",
    "\n",
    "print()\n",
    "print(\"Indexing and slicing:\")\n",
    "print(f\"First row: {tensor[0]}\")\n",
    "print(f\"First column: {tensor[:, 0]}\")\n",
    "print(f\"Last column: {tensor[..., -1]}\")\n",
    "\n",
    "tensor[:,1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "e1ddb408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n",
      "\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# This computes the matrix multiplication between two tensors\n",
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "print(y1)\n",
    "\n",
    "# This computes the element-wise product\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "\n",
    "print()\n",
    "print(z1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6de7b5c",
   "metadata": {},
   "source": [
    "# Automatic Differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b400e6",
   "metadata": {},
   "source": [
    "When training neural networks, the most frequently used algorithm is back propagation, where parameters (model weights) are adjusted according to the gradient of the loss function with respect to the given parameter.\n",
    "\n",
    "To compute those gradients, PyTorch has a built-in differentiation engine called `torch.autograd`. It supports automatic computation of gradient for any computational graph.\n",
    "\n",
    "Consider the simplest one-layer neural network, with input $x$, parameters $w$ and $b$, and some loss function. It can be defined in PyTorch in the following manner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "59dc14ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(5)  # input tensor\n",
    "y = torch.zeros(3)  # expected output\n",
    "\n",
    "# our parameters\n",
    "w = torch.randn(5, 3, requires_grad=True)\n",
    "b = torch.randn(3, requires_grad=True)\n",
    "\n",
    "# the prediction\n",
    "z = torch.matmul(x, w) + b\n",
    "\n",
    "# loss function\n",
    "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20af5f86",
   "metadata": {},
   "source": [
    "The code above defines the following computational graph:\n",
    "![sing_layer](https://pytorch.org/tutorials/_images/comp-graph.png)\n",
    "\n",
    "\n",
    "In this network, $w$ and $b$ are parameters, which we need to optimize. Thus, we need to be able to compute the gradients of loss function with respect to those variables. In order to do that, we set the `requires_grad` property of those tensors.\n",
    "\n",
    "#### Computing Gradients\n",
    "\n",
    "To optimize weights of parameters in the neural network, we need to compute the derivatives of our loss function with respect to parameters, namely, we need $\\frac{\\partial loss}{\\partial w}$ and $\\frac{\\partial loss}{\\partial b}$ under some fixed values of $x$ and $y$. To compute those derivatives, we call `loss.backward()`, and then retrieve the values from `w.grad` and `b.grad`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "500311da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2233, 0.2047, 0.0145],\n",
      "        [0.2233, 0.2047, 0.0145],\n",
      "        [0.2233, 0.2047, 0.0145],\n",
      "        [0.2233, 0.2047, 0.0145],\n",
      "        [0.2233, 0.2047, 0.0145]])\n",
      "tensor([0.2233, 0.2047, 0.0145])\n"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ac5567",
   "metadata": {},
   "source": [
    "### Datasets and DataLoaders\n",
    "\n",
    "Code for processing data samples can get messy and hard to maintain. We ideally want our dataset code to be decoupled from our model training code for better readability and modularity. PyTorch provides two data primitives: `torch.utils.data.DataLoader` and `torch.utils.data.Dataset` that allow you to use pre-loaded datasets as well as your own data. Dataset stores the samples and their corresponding labels, and DataLoader wraps an iterable around the Dataset to enable easy access to the samples for training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d42239",
   "metadata": {},
   "source": [
    "A custom Dataset class must implement three functions: `__init__`, `__len__`, and `__getitem__`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "39dcf54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, number_list):\n",
    "        self._num_list = number_list\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self._num_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        num = self._num_list[idx]\n",
    "        return torch.tensor(num), torch.tensor(num ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "433499d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(3), tensor(9))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_dataset = CustomDataset(list(range(55)))\n",
    "\n",
    "print(len(custom_dataset))\n",
    "custom_dataset[3]  # Indexing a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6211c76d",
   "metadata": {},
   "source": [
    "The Dataset retrieves our dataset’s features and labels one sample at a time. While training a model, we typically want to pass samples in “minibatches”, reshuffle the data at every epoch to reduce model overfitting, and use Python’s multiprocessing to speed up data retrieval.\n",
    "\n",
    "DataLoader is an iterable that abstracts this complexity for us in an easy API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e6ff840b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10]) tensor([  0,   1,   4,   9,  16,  25,  36,  49,  64,  81, 100])\n",
      "tensor([11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]) tensor([121, 144, 169, 196, 225, 256, 289, 324, 361, 400, 441])\n",
      "tensor([22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]) tensor([ 484,  529,  576,  625,  676,  729,  784,  841,  900,  961, 1024])\n",
      "tensor([33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43]) tensor([1089, 1156, 1225, 1296, 1369, 1444, 1521, 1600, 1681, 1764, 1849])\n",
      "tensor([44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54]) tensor([1936, 2025, 2116, 2209, 2304, 2401, 2500, 2601, 2704, 2809, 2916])\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(custom_dataset, batch_size=11, shuffle=False)\n",
    "\n",
    "for num_batch, squared_num_batch in train_dataloader:\n",
    "    print(num_batch, squared_num_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4df188bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10]) tensor([  0,   1,   4,   9,  16,  25,  36,  49,  64,  81, 100])\n",
      "tensor([11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]) tensor([121, 144, 169, 196, 225, 256, 289, 324, 361, 400, 441])\n",
      "tensor([22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]) tensor([ 484,  529,  576,  625,  676,  729,  784,  841,  900,  961, 1024])\n",
      "tensor([33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43]) tensor([1089, 1156, 1225, 1296, 1369, 1444, 1521, 1600, 1681, 1764, 1849])\n",
      "tensor([44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54]) tensor([1936, 2025, 2116, 2209, 2304, 2401, 2500, 2601, 2704, 2809, 2916])\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(custom_dataset, batch_size=11, shuffle=True)\n",
    "\n",
    "for num_batch, squared_num_batch in train_dataloader:\n",
    "    print(num_batch, squared_num_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2de0ec9",
   "metadata": {},
   "source": [
    "# The MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "31ea2723",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "USE_CUDA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8d7e70ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads and batches MNIST \n",
    "def setup_data_loaders(batch_size=128, use_cuda=False):\n",
    "    root = './data'\n",
    "    download = True\n",
    "    \n",
    "    # Download the MNIST train and test datasets, and transform the images and labels to tensors\n",
    "    trans = transforms.ToTensor()\n",
    "    train_set = MNIST(root=root, train=True, transform=trans,\n",
    "                      download=download)\n",
    "    test_set = MNIST(root=root, train=False, transform=trans)\n",
    "\n",
    "    # Build the dataloaders for the train and test sets\n",
    "    kwargs = {\"num_workers\": 1, \"pin_memory\": use_cuda}\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_set,\n",
    "        batch_size=batch_size, shuffle=True, **kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_set,\n",
    "        batch_size=batch_size, shuffle=False, **kwargs)\n",
    "    \n",
    "    return train_loader, test_loader, train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4c33f1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    mnist_train_loader, \n",
    "    mnist_test_loader, \n",
    "    mnist_train_set, \n",
    "    mnist_test_set\n",
    ") = setup_data_loaders(batch_size=BATCH_SIZE, use_cuda=USE_CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "4ea12b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# Each dataset item is a Tuple of (pixel tensor, label)\n",
    "print(mnist_train_set[11][0].shape)\n",
    "print(mnist_train_set[11][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "0dc7a9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAOHUlEQVR4nO3de+zddX3H8edLxFBRLpWtaygXuWSRbBkuDTNbdRirsGZL8Y+hJG5dZKlLJJuJW0bYFtjF2ZjpLlliVpFRwQFGcBBGVIabDJcJxdRaZdjOgFAL5SIUNzJLee+P8+3yo/5+53c5V36f5yM5+X3P9/M93/P+nfb1+3xv5/tJVSFp+XvFpAuQNB6GXWqEYZcaYdilRhh2qRGGXWqEYW9Ekn9N8pvDfm2SK5JcPVh1GgfD/jKT5KEk6yddx2FV9edVteg/IkkuS7I9yf8muXYEpekIr5x0AWrW94A/Ay4AVky4libYsy8TSU5McnuSJ5J8v5tec8RiZya5N8mBJLcmWTnj9W9K8u9Jnkny9STnL/B9r0pyfTd9TJLrkzzVree+JKtme11V3VJV/wg8taRfWItm2JePVwB/D5wGnAo8D/ztEcv8OvBeYDXwAvA3AElOBv6JXk+7Evhd4OYkP7bIGjYBxwOnAK8DfqurQ1PAsC8TVfVUVd1cVf9TVc8BHwJ+8YjFrquqXVX138AfARcnOQp4D3BHVd1RVS9W1Z3AdmDDIss4SC/kZ1XVoaq6v6oODPabaVgM+zKR5NVJ/i7Jw0kOAHcDJ3RhPuyRGdMPA0cDJ9HbGvjVbtP7mSTPAOvobQEsxnXAF4Abk3wvyUeSHL3U30nDZdiXjw8CPwn8XFUdB7ylm58Zy5wyY/pUej3xk/T+CFxXVSfMeBxbVVsWU0BVHayqP66qc4CfB36Z3q6DpoBhf3k6ujsYdvjxSuC19PaPn+kOvF05y+vek+ScJK8G/gT4bFUdAq4HfiXJBUmO6tZ5/iwH+PpK8tYkP91tTRyg98fkxTmWfWWSY4CjgKNm/B4aEcP+8nQHvWAfflwF/BW9U1hPAv8BfH6W110HXAs8BhwD/DZAVT0CbASuAJ6g19P/Hov///ETwGfpBf0B4Mvde87mD7vaL6d3zOD5bp5GJN68QmqDPbvUCMMuNcKwS40w7FIjxnqqI4lHA6URq6rMNn+gnj3JhUkeTLInyeWDrEvSaC351Ft34cS3gbcDjwL3AZdU1bf6vMaeXRqxUfTs5wF7quo7VfVD4EZ6F2ZImkKDhP1kXvrFike7eS+RZHN3R5LtA7yXpAGN/ABdVW0FtoKb8dIkDdKz7+Wl36Ja082TNIUGCft9wNlJXp/kVcC7gduGU5akYVvyZnxVvZDkMno3KzgKuKaqvjm0yiQN1Vi/9eY+uzR6I7moRtLLh2GXGmHYpUYYdqkRhl1qhGGXGmHYpUYYdqkRhl1qhGGXGmHYpUYYdqkRhl1qhGGXGmHYpUYYdqkRhl1qhGGXGmHYpUYYdqkRhl1qxFiHbNb0ufTSS/u2X3311X3b77nnnr7tb37zmxddk0bDnl1qhGGXGmHYpUYYdqkRhl1qhGGXGmHYpUY4imvjVq1a1bd93759fdufeOKJgdav4ZtrFNeBLqpJ8hDwHHAIeKGq1g6yPkmjM4wr6N5aVU8OYT2SRsh9dqkRg4a9gC8muT/J5tkWSLI5yfYk2wd8L0kDGHQzfl1V7U3y48CdSf6zqu6euUBVbQW2ggfopEkaqGevqr3dz/3A54DzhlGUpOFbctiTHJvktYengXcAu4ZVmKThGmQzfhXwuSSH1/MPVfX5oVSlsdmwYcOkS9CYLDnsVfUd4GeGWIukEfLUm9QIwy41wrBLjTDsUiMMu9QIbyXduBNOOGHSJWhM7NmlRhh2qRGGXWqEYZcaYdilRhh2qRGGXWqEt5Je5k477bS+7Tt27Ojbfvzxx/dt91bS02euW0nbs0uNMOxSIwy71AjDLjXCsEuNMOxSIwy71Ai/z77MrVixom/7fOfRu1uFz2n//v2LrkmTYc8uNcKwS40w7FIjDLvUCMMuNcKwS40w7FIjPM/euEHvZ3D77bcPqRKN2rw9e5JrkuxPsmvGvJVJ7kyyu/t54mjLlDSohWzGXwtceMS8y4G7qups4K7uuaQpNm/Yq+pu4OkjZm8EtnXT24CLhluWpGFb6j77qqra100/Bsx5o7Ekm4HNS3wfSUMy8AG6qqp+N5Ksqq3AVvCGk9IkLfXU2+NJVgN0P/3qkzTllhr224BN3fQm4NbhlCNpVObdjE9yA3A+cFKSR4ErgS3AZ5JcCjwMXDzKIjW9vvvd7066BC3QvGGvqkvmaHrbkGuRNEJeLis1wrBLjTDsUiMMu9QIwy41wq+4aiBf+tKXJl2CFsieXWqEYZcaYdilRhh2qRGGXWqEYZcaYdilRhh2qRGGXWqEYZcaYdilRhh2qRGGXWqEYZcaYdilRvh99mVu3bp1fduTDNSulw97dqkRhl1qhGGXGmHYpUYYdqkRhl1qhGGXGuF59mXurLPO6tteVX3bDx482Lf90KFDi65JkzFvz57kmiT7k+yaMe+qJHuT7OgeG0ZbpqRBLWQz/lrgwlnm/2VVnds97hhuWZKGbd6wV9XdwNNjqEXSCA1ygO6yJDu7zfwT51ooyeYk25NsH+C9JA1oqWH/OHAmcC6wD/joXAtW1daqWltVa5f4XpKGYElhr6rHq+pQVb0IfAI4b7hlSRq2JYU9yeoZT98J7JprWUnTYd7z7EluAM4HTkryKHAlcH6Sc4ECHgLeN7oSNYj169cP9Pp77723b/uePXsGWr/GZ96wV9Uls8z+5AhqkTRCXi4rNcKwS40w7FIjDLvUCMMuNcKvuC5zp5566qRL0JSwZ5caYdilRhh2qRGGXWqEYZcaYdilRhh2qRGGXWqEYZcaYdilRhh2qRGGXWqEYZcaYdilRhh2qRF+n32Z+8pXvtK3fePGjX3bjzvuuL7tK1as6Nv+/PPP923X+NizS40w7FIjDLvUCMMuNcKwS40w7FIjDLvUiFRV/wWSU4BPAavoDdG8tar+OslK4CbgdHrDNl9cVd+fZ13930xDt3v37r7tZ5xxRt/2JH3b3/CGN/Rtf/DBB/u2a/iqatZ/tIX07C8AH6yqc4A3Ae9Pcg5wOXBXVZ0N3NU9lzSl5g17Ve2rqq91088BDwAnAxuBbd1i24CLRlSjpCFY1D57ktOBNwJfBVZV1b6u6TF6m/mSptSCr41P8hrgZuADVXVg5r5cVdVc++NJNgObBy1U0mAW1LMnOZpe0D9dVbd0sx9PsrprXw3sn+21VbW1qtZW1dphFCxpaeYNe3pd+CeBB6rqYzOabgM2ddObgFuHX56kYVnIZvwvAL8GfCPJjm7eFcAW4DNJLgUeBi4eSYUayLPPPjvS9a9fv75vu6fepse8Ya+qe4C5Tra+bbjlSBoVr6CTGmHYpUYYdqkRhl1qhGGXGmHYpUZ4K+llbsuWLX3bb7rppoHWv2bNmoFer/GxZ5caYdilRhh2qRGGXWqEYZcaYdilRhh2qRHz3kp6qG/mraTHbr4hld/1rnf1bf/whz/ct/2CCy7o275z586+7Rq+QW4lLWkZMOxSIwy71AjDLjXCsEuNMOxSIwy71AjPs0vLjOfZpcYZdqkRhl1qhGGXGmHYpUYYdqkRhl1qxLxhT3JKkn9J8q0k30zyO938q5LsTbKje2wYfbmSlmrei2qSrAZWV9XXkrwWuB+4CLgY+EFV/cWC38yLaqSRm+uimnlHhKmqfcC+bvq5JA8AJw+3PEmjtqh99iSnA28EvtrNuizJziTXJDlxjtdsTrI9yfbBSpU0iAVfG5/kNcCXgQ9V1S1JVgFPAgX8Kb1N/ffOsw4346URm2szfkFhT3I0cDvwhar62CztpwO3V9VPzbMewy6N2JK/CJMkwCeBB2YGvTtwd9g7gV2DFilpdBZyNH4d8G/AN4AXu9lXAJcA59LbjH8IeF93MK/fuuzZpREbaDN+WAy7NHp+n11qnGGXGmHYpUYYdqkRhl1qhGGXGmHYpUYYdqkRhl1qhGGXGmHYpUYYdqkRhl1qhGGXGjHvDSeH7Eng4RnPT+rmTaNprW1a6wJrW6ph1nbaXA1j/T77j7x5sr2q1k6sgD6mtbZprQusbanGVZub8VIjDLvUiEmHfeuE37+faa1tWusCa1uqsdQ20X12SeMz6Z5d0pgYdqkREwl7kguTPJhkT5LLJ1HDXJI8lOQb3TDUEx2frhtDb3+SXTPmrUxyZ5Ld3c9Zx9ibUG1TMYx3n2HGJ/rZTXr487Hvsyc5Cvg28HbgUeA+4JKq+tZYC5lDkoeAtVU18QswkrwF+AHwqcNDayX5CPB0VW3p/lCeWFW/PyW1XcUih/EeUW1zDTP+G0zwsxvm8OdLMYme/TxgT1V9p6p+CNwIbJxAHVOvqu4Gnj5i9kZgWze9jd5/lrGbo7apUFX7qupr3fRzwOFhxif62fWpaywmEfaTgUdmPH+U6RrvvYAvJrk/yeZJFzOLVTOG2XoMWDXJYmYx7zDe43TEMONT89ktZfjzQXmA7ketq6qfBX4JeH+3uTqVqrcPNk3nTj8OnElvDMB9wEcnWUw3zPjNwAeq6sDMtkl+drPUNZbPbRJh3wucMuP5mm7eVKiqvd3P/cDn6O12TJPHD4+g2/3cP+F6/l9VPV5Vh6rqReATTPCz64YZvxn4dFXd0s2e+Gc3W13j+twmEfb7gLOTvD7Jq4B3A7dNoI4fkeTY7sAJSY4F3sH0DUV9G7Cpm94E3DrBWl5iWobxnmuYcSb82U18+POqGvsD2EDviPx/AX8wiRrmqOsM4Ovd45uTrg24gd5m3UF6xzYuBV4H3AXsBv4ZWDlFtV1Hb2jvnfSCtXpCta2jt4m+E9jRPTZM+rPrU9dYPjcvl5Ua4QE6qRGGXWqEYZcaYdilRhh2qRGGXWqEYZca8X/tznCqGuT7VAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_mnist_img(pixels, label):    \n",
    "    pixels = pixels.numpy()\n",
    "    pixels = pixels.reshape((28, 28))\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(f\"Label is {label}\")\n",
    "    plt.imshow(pixels, cmap=\"gray\")\n",
    "    \n",
    "for _ in range(5):\n",
    "    rand_item = random.choice(mnist_test_set)\n",
    "    pixels_tensor, label = rand_item\n",
    "    \n",
    "    plot_mnist_img(pixels_tensor, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c367f310",
   "metadata": {},
   "source": [
    "# Define the Encoder and Decoder Modules\n",
    "\n",
    "We define our neural network by subclassing `nn.Module`, and initialize the neural network layers in `__init__`. Every `nn.Module` subclass implements the operations on input data in the `forward()` method.\n",
    "\n",
    "The `forward()` method of the encoder expects as argument a tensor of dimensions *batch_dim* x 28 x 28, and infers the mean and log variance of the latent space Gaussians. Conversely, the decoder takes a tensor of dimensions *batch_dim* x *latent_space_size* and reconstructs the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "87f12828",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, z_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Setup three linear transformations\n",
    "        self.fc1 = nn.Linear(784, hidden_dim)\n",
    "        self.fc21 = nn.Linear(hidden_dim, z_dim)\n",
    "        self.fc22 = nn.Linear(hidden_dim, z_dim)\n",
    "        \n",
    "        # Setup the non-linearities\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Define the forward computation on the image x\n",
    "        # First shape the mini-batch to have pixels in the rightmost dimension\n",
    "        x = x.reshape(-1, 784)\n",
    "        \n",
    "        # Then compute the hidden units\n",
    "        hidden = self.softplus(self.fc1(x))\n",
    "        \n",
    "        # Return a mean vector and a the log variance\n",
    "        # each of size batch_size x z_dim\n",
    "        z_loc = self.fc21(hidden)\n",
    "        z_logvar = self.fc22(hidden)\n",
    "        \n",
    "        return z_loc, z_logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "322844df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, z_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Setup the two linear transformations used\n",
    "        self.fc1 = nn.Linear(z_dim, hidden_dim)\n",
    "        self.fc21 = nn.Linear(hidden_dim, 784)\n",
    "        \n",
    "        # Setup the non-linearities\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, z):\n",
    "        # Define the forward computation on the latent z\n",
    "        # first compute the hidden units\n",
    "        hidden = self.softplus(self.fc1(z))\n",
    "        \n",
    "        # Return the parameter for the output Bernoulli\n",
    "        # each is of size batch_size x 784\n",
    "        loc_img = self.sigmoid(self.fc21(hidden))\n",
    "        loc_img = loc_img.view(-1, 28, 28)\n",
    "        \n",
    "        return loc_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "9522290c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder(\n",
      "  (fc1): Linear(in_features=784, out_features=100, bias=True)\n",
      "  (fc21): Linear(in_features=100, out_features=50, bias=True)\n",
      "  (fc22): Linear(in_features=100, out_features=50, bias=True)\n",
      "  (softplus): Softplus(beta=1, threshold=20)\n",
      ")\n",
      "Decoder(\n",
      "  (fc1): Linear(in_features=50, out_features=100, bias=True)\n",
      "  (fc21): Linear(in_features=100, out_features=784, bias=True)\n",
      "  (softplus): Softplus(beta=1, threshold=20)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(z_dim=50, hidden_dim=100)\n",
    "print(encoder)\n",
    "\n",
    "decoder = Decoder(z_dim=50, hidden_dim=100)\n",
    "print(decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ad5e23",
   "metadata": {},
   "source": [
    "# The Variational Autoencoder in PyTorch\n",
    "\n",
    "To allow the passage of the gradient, we use the reparameterization trick for the Gaussian distribution:\n",
    "$$\n",
    "    \\mathbf{z} = \\mathbf{\\mu} + \\mathbf{\\sigma} \\mathbf{\\epsilon}\n",
    "$$\n",
    "where $\\mathbf{\\epsilon} \\sim \\mathcal{N}(0, 1)$\n",
    "\n",
    "Our loss function is the ELBO:\n",
    "$$\n",
    "    \\textrm{ELBO} = \\mathbb{E}_{q_{\\lambda} (\\mathbf{z})} \\left[ \\log p_{\\theta} (\\mathbf{x}, \\mathbf{z}) - \\log q_{\\lambda} (\\mathbf{z}) \\right]\n",
    "$$\n",
    "$$\n",
    "    \\textrm{ELBO} = \\mathbb{E}_{q_{\\lambda} (\\mathbf{z})} \\left[ \\log p_{\\theta}(\\mathbf{x} \\mid \\mathbf{z}) \\right] - D_{\\text{KL}} \\left[ q_{\\lambda}(\\mathbf{z} \\mid \\mathbf{x}) \\mid \\mid p_{\\theta}(\\mathbf{z}) \\right]\n",
    "$$\n",
    "We've chosen as our variational family a mean-field Gaussian posterior for our latent space. We can thus derive and use the closed form ELBO for Gaussian latents (see [here](https://arxiv.org/pdf/1907.08956.pdf) for a full derivation):\n",
    "$$\n",
    "    \\mathcal{L} = - \\sum_{j=1}^J \\frac{1}{2} \\left[ 1 + \\log \\sigma_j^2 - \\sigma_j^2 - \\mu_j^2 \\right] - \\frac{1}{L} \\sum_l \\mathbb{E}_{z \\sim q(z \\mid x_l)} \\left[ \\log p (x_l \\mid z_l) \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "0a06fd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAEPyTorch(nn.Module):\n",
    "    def __init__(self, z_dim=50, hidden_dim=400, use_cuda=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = Encoder(z_dim, hidden_dim)\n",
    "        self.decoder = Decoder(z_dim, hidden_dim)\n",
    "        \n",
    "        if use_cuda:\n",
    "            # calling cuda() here will put all the parameters of\n",
    "            # the encoder and decoder networks into GPU memory\n",
    "            self.cuda()\n",
    "            \n",
    "        self.use_cuda = use_cuda\n",
    "        self.z_dim = z_dim\n",
    "        \n",
    "    def forward(self, input_data: torch.Tensor):\n",
    "        mu, logvar = self.encoder(input_data)\n",
    "        latent_sample = self.reparameterize(mu, logvar)\n",
    "        reconstructed_inputs = self.decoder(latent_sample)\n",
    "        \n",
    "        return input_data, reconstructed_inputs, mu, logvar\n",
    "    \n",
    "    def reparameterize(self, mu: torch.Tensor, logvar: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Reparameterization trick to sample from N(mu, var) from\n",
    "        N(0,1).\n",
    "        :param mu: (Tensor) Mean of the latent Gaussian [B x D]\n",
    "        :param logvar: (Tensor) Standard deviation of the latent Gaussian [B x D]\n",
    "        :return: (Tensor) [B x D]\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        \n",
    "        return mu + std * eps\n",
    "    \n",
    "    \n",
    "    def loss_function(\n",
    "        self, input_data, reconstructions, mu, logvar, beta\n",
    "    ) -> dict:\n",
    "        \"\"\"\n",
    "        Computes the VAE loss function.\n",
    "        KL(N(\\mu, \\sigma), N(0, 1)) = \\log \\frac{1}{\\sigma} + \\frac{\\sigma^2 + \\mu^2}{2} - \\frac{1}{2}\n",
    "        :param args:\n",
    "        :param kwargs:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        recons_loss = torch_functional.mse_loss(reconstructions, input_data)\n",
    "        kld_loss = torch.mean(-0.5 * torch.sum(1 + logvar - mu ** 2 - logvar.exp(), dim = 1), dim = 0)\n",
    "\n",
    "        loss = recons_loss + beta * kld_loss\n",
    "        \n",
    "        return {\"total_loss\": loss, \"reconstruction_loss\": recons_loss.detach(), \"KLD\": -kld_loss.detach()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a8b730",
   "metadata": {},
   "source": [
    "Now that we have our data and our model we can proceed with training.\n",
    "\n",
    "\n",
    "Inside the training loop, optimization happens in three steps:\n",
    " - Call `optimizer.zero_grad()` to reset the gradients of model parameters. Gradients by default add up; to prevent double-counting, we explicitly zero them at each iteration.\n",
    " - Backpropagate the prediction loss with a call to `loss.backward()`. PyTorch deposits the gradients of the loss w.r.t. each parameter.\n",
    " - Once we have our gradients, we call `optimizer.step()` to adjust the parameters by the gradients collected in the backward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f395cf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 1\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d4375d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_pytorch = VAEPyTorch(z_dim=50, hidden_dim=100)\n",
    "optimizer = torch.optim.Adam(vae_pytorch.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "21ab74c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_387442/1779618987.py:47: UserWarning: Using a target size (torch.Size([32, 1, 28, 28])) that is different to the input size (torch.Size([32, 28, 28])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  recons_loss = torch_functional.mse_loss(reconstructions, input_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_num: 1; batch_num: 0; loss: 0.063515\n",
      "epoch_num: 1; batch_num: 400; loss: 0.069955\n",
      "epoch_num: 1; batch_num: 800; loss: 0.071728\n",
      "epoch_num: 1; batch_num: 1200; loss: 0.065966\n",
      "epoch_num: 1; batch_num: 1600; loss: 0.069113\n",
      "epoch_num: 2; batch_num: 0; loss: 0.060997\n",
      "epoch_num: 2; batch_num: 400; loss: 0.067108\n",
      "epoch_num: 2; batch_num: 800; loss: 0.064268\n",
      "epoch_num: 2; batch_num: 1200; loss: 0.065890\n",
      "epoch_num: 2; batch_num: 1600; loss: 0.070844\n",
      "epoch_num: 3; batch_num: 0; loss: 0.069434\n",
      "epoch_num: 3; batch_num: 400; loss: 0.066980\n",
      "epoch_num: 3; batch_num: 800; loss: 0.067134\n",
      "epoch_num: 3; batch_num: 1200; loss: 0.066142\n",
      "epoch_num: 3; batch_num: 1600; loss: 0.064702\n",
      "epoch_num: 4; batch_num: 0; loss: 0.070319\n",
      "epoch_num: 4; batch_num: 400; loss: 0.063016\n",
      "epoch_num: 4; batch_num: 800; loss: 0.064162\n",
      "epoch_num: 4; batch_num: 1200; loss: 0.067914\n",
      "epoch_num: 4; batch_num: 1600; loss: 0.070054\n",
      "epoch_num: 5; batch_num: 0; loss: 0.075909\n",
      "epoch_num: 5; batch_num: 400; loss: 0.072080\n",
      "epoch_num: 5; batch_num: 800; loss: 0.062604\n",
      "epoch_num: 5; batch_num: 1200; loss: 0.065996\n",
      "epoch_num: 5; batch_num: 1600; loss: 0.071502\n"
     ]
    }
   ],
   "source": [
    "for epoch_num in range(NUM_EPOCHS):\n",
    "    for batch_num, (pixels, _) in enumerate(mnist_train_loader):\n",
    "        if USE_CUDA:\n",
    "            pixels = pixels.to(\"cuda\")\n",
    "            labels = labels.to(\"cuda\")\n",
    "        \n",
    "        # Do NOT use directly forward()!\n",
    "        input_data, reconstructed_inputs, mu, logvar = vae_pytorch(pixels)\n",
    "        losses = vae_pytorch.loss_function(\n",
    "            pixels, reconstructed_inputs, mu, logvar, 0.1\n",
    "        )\n",
    "        loss = losses[\"total_loss\"]\n",
    "        \n",
    "        # Backpropagation and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_num % 400 == 0:\n",
    "            print(f\"epoch_num: {epoch_num + 1}; batch_num: {batch_num}; loss: {loss.item():>7f}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "a08a1260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rand_item = random.choice(mnist_test_set)\n",
    "pixels_tensor, label = rand_item\n",
    "\n",
    "_, reconstructed_inputs, _, _ = vae_pytorch(pixels_tensor)\n",
    "reconstructed_pixels = reconstructed_inputs.detach()\n",
    "\n",
    "plot_mnist_img(pixels_tensor, label)\n",
    "plot_mnist_img(reconstructed_pixels, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfab340",
   "metadata": {},
   "source": [
    "# The Variational Autoencoder in Pyro\n",
    "\n",
    "Probabilistic models in Pyro are specified as Python functions `model(*args, **kwargs)` that generate observed data from latent variables using special primitive functions whose behavior can be changed by Pyro’s internals depending on the high-level computation being performed.\n",
    "\n",
    "Specifically, the different mathematical pieces of `model()` are encoded via the mapping:\n",
    " + latent random variables - `pyro.sample`\n",
    " + observed random variables - `pyro.sample` with the `obs` keyword argument\n",
    " + learnable parameters - `pyro.param`\n",
    " + plates - `pyro.plate` context managers\n",
    " \n",
    "The basic idea behind VI is that we introduce a parameterized distribution $q_{\\phi}(\\mathbf{z})$ called the variational distribution that will serve as an approximation to the posterior. We can think of $\\phi$ as parameterizing a space or family of probability distributions. Our goal will be to find the (not necessarily unique) probability distribution in that space that is the best possible approximation to the posterior distribution.\n",
    "\n",
    "Just like the model, the guide is encoded as a stochastic function `guide()` that contains `pyro.sample` and `pyro.param` statements, but can't contain observed data. Pyro furthermore enforces that `model()` and `guide()` have the same call signature, i.e. both callables should take the same arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "beffedc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAEPyro(nn.Module):\n",
    "    def __init__(self, z_dim=50, hidden_dim=400, use_cuda=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Create the encoder and decoder networks\n",
    "        self.encoder = Encoder(z_dim, hidden_dim)\n",
    "        self.decoder = Decoder(z_dim, hidden_dim)\n",
    "\n",
    "        if use_cuda:\n",
    "            # calling cuda() here will put all the parameters of\n",
    "            # the encoder and decoder networks into gpu memory\n",
    "            self.cuda()\n",
    "        \n",
    "        self.use_cuda = use_cuda\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "    # Define the model p(x|z)p(z)\n",
    "    def model(self, x):\n",
    "        # register PyTorch module `decoder` with Pyro\n",
    "        pyro.module(\"decoder\", self.decoder)\n",
    "        \n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            # setup hyperparameters for prior p(z)\n",
    "            z_loc = x.new_zeros(torch.Size((x.shape[0], self.z_dim)))\n",
    "            z_scale = x.new_ones(torch.Size((x.shape[0], self.z_dim)))\n",
    "            \n",
    "            # sample from prior (value will be sampled by guide when computing the ELBO)\n",
    "            z = pyro.sample(\"latent\", dist.Normal(z_loc, z_scale).to_event(1))\n",
    "            \n",
    "            # decode the latent code z\n",
    "            loc_img = self.decoder(z).view(-1, 784)\n",
    "            # score against actual images\n",
    "            pyro.sample(\"obs\", dist.Bernoulli(loc_img).to_event(1), obs=x.reshape(-1, 784))\n",
    "        \n",
    "    # Define the guide (i.e. variational distribution) q(z|x)\n",
    "    def guide(self, x):\n",
    "        # register PyTorch module `encoder` with Pyro\n",
    "        pyro.module(\"encoder\", self.encoder)\n",
    "        \n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            # use the encoder to get the parameters used to define q(z|x)\n",
    "            z_loc, logvar = self.encoder(x)\n",
    "            z_scale = torch.exp(logvar)\n",
    "            \n",
    "            # sample the latent code z\n",
    "            pyro.sample(\"latent\", dist.Normal(z_loc, z_scale).to_event(1))\n",
    "\n",
    "    # define a helper function for reconstructing images\n",
    "    def reconstruct_img(self, x):\n",
    "        # encode image x\n",
    "        z_loc, logvar = self.encoder(x)\n",
    "        z_scale = torch.exp(logvar)\n",
    "        \n",
    "        # sample in latent space\n",
    "        z = dist.Normal(z_loc, z_scale).sample()\n",
    "        \n",
    "        # decode the image (note we don't sample in image space)\n",
    "        loc_img = self.decoder(z)\n",
    "        return loc_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "4646085c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(svi, train_loader, use_cuda=False):\n",
    "    # initialize loss accumulator\n",
    "    epoch_loss = 0.\n",
    "    # do a training epoch over each mini-batch x returned\n",
    "    # by the data loader\n",
    "    for x, _ in train_loader:\n",
    "        # if on GPU put mini-batch into CUDA memory\n",
    "        if use_cuda:\n",
    "            x = x.cuda()\n",
    "        # do ELBO gradient and accumulate loss\n",
    "        epoch_loss += svi.step(x)\n",
    "\n",
    "    # return epoch loss\n",
    "    normalizer_train = len(train_loader.dataset)\n",
    "    total_epoch_loss_train = epoch_loss / normalizer_train\n",
    "    \n",
    "    return total_epoch_loss_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "4d3e69e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(svi, test_loader, use_cuda=False):\n",
    "    # initialize loss accumulator\n",
    "    test_loss = 0.\n",
    "    # compute the loss over the entire test set\n",
    "    \n",
    "    for x, _ in test_loader:\n",
    "        # if on GPU put mini-batch into CUDA memory\n",
    "        if use_cuda:\n",
    "            x = x.cuda()\n",
    "        # compute ELBO estimate and accumulate loss\n",
    "        test_loss += svi.evaluate_loss(x)\n",
    "    \n",
    "    normalizer_test = len(test_loader.dataset)\n",
    "    total_epoch_loss_test = test_loss / normalizer_test\n",
    "    \n",
    "    return total_epoch_loss_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "811d466e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_387442/3623291631.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mtotal_epoch_loss_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mUSE_CUDA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mtrain_elbo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtotal_epoch_loss_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[epoch %03d]  average training loss: %.4f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_epoch_loss_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_387442/2149041741.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(svi, train_loader, use_cuda)\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# do ELBO gradient and accumulate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msvi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# return epoch loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyro/infer/svi.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;31m# get loss and compute gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mparam_capture\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_and_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         params = set(\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyro/infer/trace_elbo.py\u001b[0m in \u001b[0;36mloss_and_grads\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# grab a trace from the generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmodel_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide_trace\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_traces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m             loss_particle, surrogate_loss_particle = self._differentiable_loss_particle(\n\u001b[1;32m    142\u001b[0m                 \u001b[0mmodel_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide_trace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyro/infer/elbo.py\u001b[0m in \u001b[0;36m_get_traces\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_vectorized_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_particles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = mnist_train_loader, mnist_test_loader\n",
    "\n",
    "# clear param store\n",
    "pyro.clear_param_store()\n",
    "\n",
    "# setup the VAE\n",
    "vae = VAEPyro(use_cuda=USE_CUDA)\n",
    "\n",
    "# setup the optimizer\n",
    "adam_args = {\"lr\": LEARNING_RATE}\n",
    "optimizer = Adam(adam_args)\n",
    "\n",
    "# setup the inference algorithm\n",
    "svi = SVI(vae.model, vae.guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "train_elbo = []\n",
    "test_elbo = []\n",
    "# training loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    total_epoch_loss_train = train(svi, train_loader, use_cuda=USE_CUDA)\n",
    "    train_elbo.append(-total_epoch_loss_train)\n",
    "    print(\"[epoch %03d]  average training loss: %.4f\" % (epoch, total_epoch_loss_train))\n",
    "\n",
    "    if epoch % TEST_FREQUENCY == 0:\n",
    "        # report test diagnostics\n",
    "        total_epoch_loss_test = evaluate(svi, test_loader, use_cuda=USE_CUDA)\n",
    "        test_elbo.append(-total_epoch_loss_test)\n",
    "        print(\"[epoch %03d] average test loss: %.4f\" % (epoch, total_epoch_loss_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "594ca032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rand_item = random.choice(mnist_test_set)\n",
    "pixels_tensor, label = rand_item\n",
    "\n",
    "reconstructed_inputs = vae.reconstruct_img(pixels_tensor)\n",
    "reconstructed_pixels = reconstructed_inputs.detach()\n",
    "\n",
    "plot_mnist_img(pixels_tensor, label)\n",
    "plot_mnist_img(reconstructed_pixels, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f589743",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e878a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80694636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "359ee62d",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "\n",
    "https://pyro.ai/examples/vae.html\n",
    "https://pytorch.org/tutorials/beginner/basics/intro.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
